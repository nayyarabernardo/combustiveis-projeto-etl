{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIDCYtjT9uOg"
      },
      "outputs": [],
      "source": [
        "#pip install --upgrade pip\n",
        "#pip install apache_beam[interactive]\n",
        "#pip install apache_beam[gcp]\n",
        "#pip install gcsfs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pipeline\n",
        "\n",
        "> Esse Colab Notebooks é referente a segunda parte do trabalho de conclusão de curso de Engenharia de dados \n",
        "\n",
        "> Para a criação do Dataframe de ‘dfcomb_etanol_trat’ os dados foram inseridos, transformados e normalizados por meio de uma PIPELINE com modelo criado em apache beam usando o dataflow para o work e enviados para um DataLake. Nesse dataframe temos uma a junção de dois dataframe anteriormentes tratados “dfbio_trat” e “dfprecos” que estavam do datalake Google Store. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XCj2QR_HTLYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "import os\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.io.textio import WriteToText\n",
        "\n",
        "colunas_bio = ['','regiao','uf','produto','volume_m3','data']\n",
        "colunas_preco = ['','data','regiao','estado','produto','postos_pesquisados','uni_medida','media_rev','desvio_rev','preco_min_rev','preco_max_rev','margem_rev','coef_var_rev','media_dist','dp_dist','preco_min_dist','preco_max_dist','coef_var_dist']\n",
        "\n",
        "def lista_dicionario(elemento, colunas):\n",
        "  return dict(zip(colunas, elemento))\n",
        "\n",
        "def trata_data(elemento):\n",
        "  # Recebe um dicionario e cria um novo campo com ANO-MES -  Retorna o mesmo dicionario com novo campo \n",
        "  elemento['ano_mes']= '-'.join(elemento['data'].split('-')[:2])\n",
        "  return elemento\n",
        "\n",
        "def chave_uf(elemento):\n",
        "#  Receber um dicionario -   Retorna uma tupla com estado e o elemento(UF, dicionario )\n",
        "  chave = elemento['uf']\n",
        "  return (chave, elemento)\n",
        "\n",
        "def volume(elemento):\n",
        "  #  Recebe um tupla ('SAO PAULO', [{},{}]) -   Retorna uma tupla ('SAO PAULO', 8.0)\n",
        "\n",
        "  uf, registros = elemento\n",
        "  for registros in registros:\n",
        "    yield (f\"{uf}-{registros['ano_mes']}\", float(registros['volume_m3']))\n",
        "\n",
        "def chave_estado(elemento):\n",
        "  chave = elemento['estado']\n",
        "  return (chave, elemento)\n",
        "\n",
        "def media_rev(elemento):\n",
        "  estado, registros = elemento\n",
        "  for registros in registros:\n",
        "    yield (f\"{estado}-{registros['ano_mes']}\", float(registros['media_rev']))\n",
        "\n",
        "def arredonda(elemento):\n",
        "  #Recebe uma tupla e retorna uma tupla com valor arredondado  \n",
        "  chave, valor = elemento\n",
        "  return (chave, round(valor,2))\n",
        "\n",
        "def filtra_campos_vazios(elemento):\n",
        "  #Remove elementos que tenham chaves vazias] -   Receber uam tupla e retorna a mesma dupla sem campos vazios   \n",
        "  chave, dados = elemento\n",
        "  if all([\n",
        "      dados['volume_m3'],\n",
        "      dados['valor_media_rev']\n",
        "      ]):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def descompactar_elementos(elemento):\n",
        "  #Receber uma tupla ('DISTRITO FEDERAL-2015-10', {'volume_m3': [4.0], 'valor_media_rev': [11.67]})   Retorna uma tupla ('DISTRITO FEDERAL', '2015', '10', '4.0', '11.67')  \n",
        "  chave, dados = elemento\n",
        "  volume_m3 = dados['volume_m3'][0] #acessando o primeiro elemento dessa lista [0]\n",
        "  valor_media_rev = dados['valor_media_rev'][0]\n",
        "  uf, ano, mes = chave.split('-')\n",
        "  return uf, ano, mes, str(volume_m3), str(valor_media_rev)  #transformar em str para poder usar o join posteriomente\n",
        "\n",
        "def preparar_csv(elemento, deliminator=','):\n",
        "  #Recebe uma tupla e retorna uma string delimitada \"DISTRITO FEDERAL;2015;10;4.0;11.67\"\n",
        "  return f\"{deliminator}\".join(elemento)\n",
        "\n",
        "\n",
        "pipeline_options = {\n",
        "    'project':'sc-bc26-ed7',\n",
        "    'runner':'DataflowRunner',\n",
        "    'region':'southamerica-east1',\n",
        "    'staging_location':'gs://projeto-final-equipe4/beam/staging/',\n",
        "    'temp_location':'gs://projeto-final-equipe4/beam/temp/',\n",
        "    'template_location':'gs://projeto-final-equipe4/beam/models/modelo_batch'\n",
        "}\n",
        "\n",
        "serviceAccount = '/content/sc-bc26-ed7-adb0dc2607d9.json'\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = serviceAccount\n",
        "\n",
        "pipeline_options = PipelineOptions.from_dictionary(pipeline_options)\n",
        "\n",
        "p1 = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "biocombustiveis = (\n",
        "    p1\n",
        "    |'Extrair do CSV bio'>> beam.io.ReadFromText('gs://projeto-final-equipe4/arquivos_trat/dfbio_trat', skip_header_lines=1)  \n",
        "    |'Sep de dados'>> beam.Map(lambda record: record.split(','))\n",
        "    |'Filt por produto'>> beam.Filter(lambda record: str(record[3])== 'HIDRATADO')\n",
        "    |'Tranf lista para dic'>>beam.Map(lista_dicionario, colunas_bio)\n",
        "    |'Criar Campo ano_mes'>>beam.Map(trata_data)\n",
        "    |'Criar chave pelo uf'>> beam.Map(chave_uf)\n",
        "    |'Agrupar pelo uf'>>beam.GroupByKey()\n",
        "    |'Descompactar vol'>>beam.FlatMap(volume)\n",
        "    |'Media dos vol pela chave'>> beam.CombinePerKey(sum)\n",
        "    |'Arredondar resultados'>>beam.Map(arredonda)\n",
        "    #|'Imprimir o resultado'>> beam.Map(print)\n",
        ")\n",
        "\n",
        "precos = (\n",
        "    p1\n",
        "    |'Extrair do CSV Preços'>> beam.io.ReadFromText('gs://projeto-final-equipe4/arquivos_trat/dfprecos.csv', skip_header_lines=1) \n",
        "    |'Sep de dados Preços'>> beam.Map(lambda record: record.split(',')) \n",
        "    |'Filt por prod Preços'>> beam.Filter(lambda record: str(record[4])== 'ETANOL HIDRATADO')\n",
        "    |'Tranformar lista para dic Preços'>>beam.Map(lista_dicionario, colunas_preco)\n",
        "    |'Criar Campo ano_mes Preços'>>beam.Map(trata_data) \n",
        "    |'Criar chave pelo est Preços'>> beam.Map(chave_estado)\n",
        "    |'Agrupar estado Preços'>>beam.GroupByKey()\n",
        "    |'Descompactar vol Preços'>>beam.FlatMap(media_rev)\n",
        "    |'Media preços'>> beam.combiners.Mean.PerKey()\n",
        "    |'Arredondar preços'>>beam.Map(arredonda)\n",
        "    #|'Imprimir o resultado Dataset Preços'>> beam.Map(print)\n",
        ")\n",
        "\n",
        "resultado = (\n",
        "    ({'volume_m3':biocombustiveis,'valor_media_rev':precos})\n",
        "    |'Mesclar pcol'>>beam.CoGroupByKey()\n",
        "    |'Filtrar dados vazios'>>beam.Filter(filtra_campos_vazios)\n",
        "    |'Descompactar'>>beam.Map(descompactar_elementos)   \n",
        "    |'Preparar csv'>>beam.Map(preparar_csv, deliminator=',')\n",
        "    #|'Imprimir o resultado da união'>> beam.Map(print)\n",
        ")\n",
        "\n",
        "# uf, ano, mes, str(volume_m3), str(valor_media_rev)\n",
        "header = 'UF,ano,volume_m3,valor_media_rev'\n",
        "resultado |'Criar arquivo CSV'>> beam.io.WriteToText('gs://projeto-final-equipe4/arquivos_trat/dfcomb_etanol_trat', file_name_suffix='.csv', header=header)\n",
        "\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "qC5ONLTZTFZs",
        "outputId": "db4a8572-07cd-4484-92e0-8681ad15fed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    div.alert {\n",
              "      white-space: pre-line;\n",
              "    }\n",
              "  </style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css\" integrity=\"sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh\" crossorigin=\"anonymous\">\n",
              "            <div class=\"alert alert-info\">No cache_root detected. Defaulting to staging_location gs://projeto-final-equipe4/beam/staging/ for cache location.</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DataflowPipelineResult None at 0x7fddc31fd940>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1aEffE-PzwjD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}